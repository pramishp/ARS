{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pybullet_envs\n",
    "import gym\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "num_steps = 1000 # step size\n",
    "num_direction = 60 # number of direction per iteration N \n",
    "num_top_direction = 20 #num of top performing direction to use ; b < N\n",
    "assert num_direction >= num_top_direction\n",
    "noise = 0.025\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer():\n",
    "    \n",
    "    def __init__(self, nb_inputs):\n",
    "        self.n = np.zeros(nb_inputs)\n",
    "        self.mean = np.zeros(nb_inputs)\n",
    "        self.mean_diff = np.zeros(nb_inputs)\n",
    "        self.var = np.zeros(nb_inputs)\n",
    "    \n",
    "    def observe(self, x):\n",
    "        self.n += 1.\n",
    "        last_mean = self.mean.copy()\n",
    "        self.mean += (x - self.mean) / self.n\n",
    "        self.mean_diff += (x - last_mean) * (x - self.mean)\n",
    "        self.var = (self.mean_diff / self.n).clip(min = 1e-2)\n",
    "    \n",
    "    def normalize(self, inputs):\n",
    "        obs_mean = self.mean\n",
    "        obs_std = np.sqrt(self.var)\n",
    "        return (inputs - obs_mean) / obs_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "class Model(object):\n",
    "    def __init__(self, n_steps, n_directions, n_top_directions, noise,episode_length):\n",
    "        self.n_steps = n_steps # step size\n",
    "        self.n_directions = n_directions # number of direction per iteration N \n",
    "        self.n_top_directions = n_top_directions #num of top performing direction to use ; b < N\n",
    "        assert self.n_directions >= self.n_top_directions\n",
    "        self.noise = noise # v => noise \n",
    "        # -----\n",
    "        self.episode_length = episode_length\n",
    "        self.learning_rate = 0.02\n",
    "    \n",
    "    def forward_pass(self, x, delta, direction=None):\n",
    "        if direction is None:\n",
    "            return (self.M.dot(x))\n",
    "        if direction == \"positive\":\n",
    "            return (self.M + self.noise* delta).dot(x) \n",
    "        else:\n",
    "            return (self.M - self.noise* delta).dot(x)\n",
    "    \n",
    "    def update(self, sorted_deltas, std):\n",
    "        second_part = np.zeros(self.M.shape)\n",
    "        for p_reward, n_reward, delta in sorted_deltas:\n",
    "            second_part += (p_reward - n_reward)* delta\n",
    "        self.M += self.learning_rate/(self.n_top_directions*std) * second_part\n",
    "    \n",
    "    def explore(self, env, direction=None, delta=None):\n",
    "        state = env.reset()\n",
    "        done = False \n",
    "        num_plays = 0\n",
    "        sum_rewards = 0\n",
    "        while not done and num_plays < self.episode_length:\n",
    "            self.normalizer.observe(state)\n",
    "#             state = self.normalizer.normalize(state)\n",
    "            action = self.forward_pass(state, delta, direction)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            sum_rewards += max(min(reward,1),-1)\n",
    "            num_plays += 1\n",
    "        return sum_rewards\n",
    "    \n",
    "    def train(self, env,input_size, output_size):\n",
    "        self.normalizer = Normalizer(input_size)\n",
    "        self.M = np.zeros((output_size, input_size))\n",
    "        for i in range(self.n_steps):\n",
    "            sample_deltas = [np.random.randn(*self.M.shape) for _ in range(self.n_directions)]\n",
    "            deltas = sample_deltas\n",
    "            positive_rewards = [0] * self.n_directions\n",
    "            negative_rewards = [0] * self.n_directions\n",
    "            for k,delta in enumerate(sample_deltas):\n",
    "                positive_reward = self.explore(env, \"positive\", delta)\n",
    "                positive_rewards[k] = positive_reward\n",
    "            for k,delta in enumerate(sample_deltas):\n",
    "                negative_reward = self.explore(env, \"negative\", delta)\n",
    "                negative_rewards[k] = negative_reward\n",
    "\n",
    "            # sorting\n",
    "            scores = {\n",
    "                k: max(p_reward, n_reward) for k, (p_reward, n_reward) in enumerate(zip(positive_rewards, negative_rewards))\n",
    "            }\n",
    "            sorted_scores = sorted(scores.keys(), key=lambda key: scores[key], reverse=True)[:self.n_top_directions]\n",
    "            sorted_deltas = [(positive_rewards[k], negative_rewards[k], deltas[k]) for k in sorted_scores]\n",
    "            \n",
    "            # sigma r\n",
    "            all_rewards = np.array(positive_rewards+ negative_rewards)\n",
    "            sigma_r = all_rewards.std()\n",
    "            \n",
    "            self.update(sorted_deltas, sigma_r)\n",
    "            \n",
    "            result = self.explore(env)\n",
    "            print (\"Step: \", i, \"Reward: \", result)\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "WalkerBase::__init__ start\n",
      "Step:  0 Reward:  -957.4178099521027\n",
      "Step:  1 Reward:  -947.4225000665564\n",
      "Step:  2 Reward:  -932.2300342840119\n",
      "Step:  3 Reward:  -954.6621817692194\n",
      "Step:  4 Reward:  -926.1987192026969\n",
      "Step:  5 Reward:  -840.8696437183598\n",
      "Step:  6 Reward:  -931.1651768714132\n",
      "Step:  7 Reward:  -872.69450076052\n",
      "Step:  8 Reward:  -961.5361613723699\n",
      "Step:  9 Reward:  -592.9377438422657\n",
      "Step:  10 Reward:  -946.5269995017346\n",
      "Step:  11 Reward:  -536.3409299108653\n",
      "Step:  12 Reward:  -898.1993233094701\n",
      "Step:  13 Reward:  -537.6817069479624\n",
      "Step:  14 Reward:  -481.7321468539703\n",
      "Step:  15 Reward:  -441.0414019968791\n",
      "Step:  16 Reward:  -331.5919798321567\n",
      "Step:  17 Reward:  -216.690924469937\n",
      "Step:  18 Reward:  -113.44450981747447\n",
      "Step:  19 Reward:  -178.8414925940782\n",
      "Step:  20 Reward:  -178.65997957159442\n",
      "Step:  21 Reward:  -46.4866115994585\n",
      "Step:  22 Reward:  -685.1477930453004\n",
      "Step:  23 Reward:  -199.88221049566457\n",
      "Step:  24 Reward:  84.27937947621778\n",
      "Step:  25 Reward:  -53.132790735904884\n",
      "Step:  26 Reward:  -34.98539302890103\n",
      "Step:  27 Reward:  -24.513775168397117\n",
      "Step:  28 Reward:  176.27064411196315\n",
      "Step:  29 Reward:  142.0686045155928\n",
      "Step:  30 Reward:  300.8163294779883\n",
      "Step:  31 Reward:  176.16954196711265\n",
      "Step:  32 Reward:  176.92050759810277\n",
      "Step:  33 Reward:  200.38081762390436\n",
      "Step:  34 Reward:  251.627438486269\n",
      "Step:  35 Reward:  242.11159129614046\n",
      "Step:  36 Reward:  316.42632477600364\n",
      "Step:  37 Reward:  315.4120381794814\n",
      "Step:  38 Reward:  319.08800883285926\n",
      "Step:  39 Reward:  327.54527377253146\n",
      "Step:  40 Reward:  245.48205718643027\n",
      "Step:  41 Reward:  321.505846911825\n",
      "Step:  42 Reward:  343.56568757402613\n",
      "Step:  43 Reward:  317.02076310141337\n",
      "Step:  44 Reward:  327.3454034078533\n",
      "Step:  45 Reward:  461.22121229700093\n",
      "Step:  46 Reward:  421.24549945117826\n",
      "Step:  47 Reward:  447.9018671228428\n",
      "Step:  48 Reward:  326.61925386336793\n",
      "Step:  49 Reward:  427.7928800019578\n",
      "Step:  50 Reward:  381.6291642264292\n",
      "Step:  51 Reward:  376.92629535568153\n",
      "Step:  52 Reward:  435.0680701967728\n",
      "Step:  53 Reward:  399.4527376405512\n",
      "Step:  54 Reward:  491.7398642509128\n",
      "Step:  55 Reward:  463.1592706533951\n",
      "Step:  56 Reward:  481.99786450838656\n",
      "Step:  57 Reward:  514.8999531465624\n",
      "Step:  58 Reward:  445.42114094342804\n",
      "Step:  59 Reward:  468.5161868236012\n",
      "Step:  60 Reward:  464.97670319864636\n",
      "Step:  61 Reward:  450.252315155607\n",
      "Step:  62 Reward:  502.7129290787266\n",
      "Step:  63 Reward:  512.6227827406777\n",
      "Step:  64 Reward:  504.765448978407\n",
      "Step:  65 Reward:  454.4858818086674\n",
      "Step:  66 Reward:  503.63699479020534\n",
      "Step:  67 Reward:  534.2206290636724\n",
      "Step:  68 Reward:  530.6818638325192\n",
      "Step:  69 Reward:  528.7534740679013\n",
      "Step:  70 Reward:  564.211371771488\n",
      "Step:  71 Reward:  521.0591934042652\n",
      "Step:  72 Reward:  502.58255285024035\n",
      "Step:  73 Reward:  592.9692621897323\n",
      "Step:  74 Reward:  578.1896622416231\n",
      "Step:  75 Reward:  -185.331943088302\n",
      "Step:  76 Reward:  637.6254751369861\n",
      "Step:  77 Reward:  618.2934768101917\n",
      "Step:  78 Reward:  551.7349025382656\n",
      "Step:  79 Reward:  624.9035270989275\n",
      "Step:  80 Reward:  541.5527265192173\n",
      "Step:  81 Reward:  637.7722562772849\n",
      "Step:  82 Reward:  673.7027629130242\n",
      "Step:  83 Reward:  653.8794821847122\n",
      "Step:  84 Reward:  680.3699384147235\n",
      "Step:  85 Reward:  671.355700072055\n",
      "Step:  86 Reward:  655.5693389107532\n",
      "Step:  87 Reward:  607.9715962860971\n",
      "Step:  88 Reward:  657.7405021297228\n",
      "Step:  89 Reward:  698.1829206404256\n",
      "Step:  90 Reward:  636.3967679442329\n",
      "Step:  91 Reward:  696.1384253033733\n",
      "Step:  92 Reward:  681.899076993221\n",
      "Step:  93 Reward:  669.6263555053473\n",
      "Step:  94 Reward:  695.4773691004789\n",
      "Step:  95 Reward:  711.0987001401928\n",
      "Step:  96 Reward:  724.8194961785073\n",
      "Step:  97 Reward:  718.6865027852234\n",
      "Step:  98 Reward:  709.041546462616\n",
      "Step:  99 Reward:  735.1616619984947\n",
      "Step:  100 Reward:  696.6930269993709\n",
      "Step:  101 Reward:  702.8956084293714\n",
      "Step:  102 Reward:  686.5184366808919\n",
      "Step:  103 Reward:  702.205259694182\n",
      "Step:  104 Reward:  664.0423848599681\n",
      "Step:  105 Reward:  708.388478569233\n",
      "Step:  106 Reward:  705.0858603672555\n",
      "Step:  107 Reward:  695.5712347705413\n",
      "Step:  108 Reward:  724.6024490690206\n",
      "Step:  109 Reward:  721.9160528448008\n",
      "Step:  110 Reward:  739.4131166735509\n",
      "Step:  111 Reward:  732.7178887923438\n",
      "Step:  112 Reward:  729.3248833810724\n",
      "Step:  113 Reward:  737.9875190783033\n",
      "Step:  114 Reward:  729.2189958937056\n",
      "Step:  115 Reward:  734.7985456837873\n",
      "Step:  116 Reward:  757.6600614342816\n",
      "Step:  117 Reward:  760.6614540753551\n",
      "Step:  118 Reward:  738.2307949454104\n",
      "Step:  119 Reward:  731.7779862034959\n",
      "Step:  120 Reward:  717.5936540904285\n",
      "Step:  121 Reward:  746.6492360910404\n",
      "Step:  122 Reward:  696.4871529296369\n",
      "Step:  123 Reward:  744.0924444480563\n",
      "Step:  124 Reward:  741.7883510415551\n",
      "Step:  125 Reward:  725.2726646734151\n",
      "Step:  126 Reward:  731.6006642767273\n",
      "Step:  127 Reward:  721.871616633961\n",
      "Step:  128 Reward:  734.1072739535679\n",
      "Step:  129 Reward:  761.8682259983939\n",
      "Step:  130 Reward:  725.4902499957394\n",
      "Step:  131 Reward:  752.8196637782255\n",
      "Step:  132 Reward:  721.2015594097079\n",
      "Step:  133 Reward:  741.0142864931411\n",
      "Step:  134 Reward:  760.5249269826023\n",
      "Step:  135 Reward:  781.1214945657719\n",
      "Step:  136 Reward:  742.5885635647428\n",
      "Step:  137 Reward:  739.5703915595051\n",
      "Step:  138 Reward:  746.6642215365712\n",
      "Step:  139 Reward:  730.5170687294082\n",
      "Step:  140 Reward:  701.4493794279969\n",
      "Step:  141 Reward:  747.824236683526\n",
      "Step:  142 Reward:  750.8328979584556\n",
      "Step:  143 Reward:  738.7539477302329\n",
      "Step:  144 Reward:  708.7338220857214\n",
      "Step:  145 Reward:  703.4222256961161\n",
      "Step:  146 Reward:  717.5477299994757\n",
      "Step:  147 Reward:  730.794694871939\n",
      "Step:  148 Reward:  714.9872026624482\n",
      "Step:  149 Reward:  728.893122500371\n",
      "Step:  150 Reward:  719.0278545597731\n",
      "Step:  151 Reward:  727.3640591086626\n",
      "Step:  152 Reward:  742.2212998305002\n",
      "Step:  153 Reward:  723.3885770367981\n",
      "Step:  154 Reward:  744.4649194720984\n",
      "Step:  155 Reward:  738.7571844312204\n",
      "Step:  156 Reward:  720.6612542490726\n",
      "Step:  157 Reward:  707.1367335463171\n",
      "Step:  158 Reward:  733.7104121305625\n",
      "Step:  159 Reward:  719.826856142378\n",
      "Step:  160 Reward:  730.3712264123978\n",
      "Step:  161 Reward:  728.4128227099853\n",
      "Step:  162 Reward:  767.2775792758213\n",
      "Step:  163 Reward:  755.2115142851483\n",
      "Step:  164 Reward:  755.6324963546402\n",
      "Step:  165 Reward:  776.4163668975127\n",
      "Step:  166 Reward:  774.7633514728815\n",
      "Step:  167 Reward:  786.4433713391118\n",
      "Step:  168 Reward:  777.2213098435258\n",
      "Step:  169 Reward:  798.4581013428585\n",
      "Step:  170 Reward:  794.5109783359073\n",
      "Step:  171 Reward:  781.4082094369496\n",
      "Step:  172 Reward:  773.4326147330826\n",
      "Step:  173 Reward:  775.5727906551126\n",
      "Step:  174 Reward:  816.9638871726776\n",
      "Step:  175 Reward:  784.5889183402832\n",
      "Step:  176 Reward:  755.3487977934352\n",
      "Step:  177 Reward:  769.8051796945549\n",
      "Step:  178 Reward:  773.1966234895889\n",
      "Step:  179 Reward:  778.4427489272374\n",
      "Step:  180 Reward:  795.0088075309869\n",
      "Step:  181 Reward:  761.2547526513526\n",
      "Step:  182 Reward:  763.5464229787987\n",
      "Step:  183 Reward:  763.7012600760104\n",
      "Step:  184 Reward:  744.7960567890249\n",
      "Step:  185 Reward:  755.8395290847692\n",
      "Step:  186 Reward:  788.7761121180629\n",
      "Step:  187 Reward:  749.7199622897331\n",
      "Step:  188 Reward:  764.8770858214403\n",
      "Step:  189 Reward:  776.6169001341212\n",
      "Step:  190 Reward:  791.5207095217745\n",
      "Step:  191 Reward:  792.1124833238641\n",
      "Step:  192 Reward:  790.6016592817689\n",
      "Step:  193 Reward:  738.8360472237533\n",
      "Step:  194 Reward:  790.7920664599783\n",
      "Step:  195 Reward:  798.5942197754509\n",
      "Step:  196 Reward:  758.6214067632238\n",
      "Step:  197 Reward:  779.8164308299533\n",
      "Step:  198 Reward:  773.4152706023399\n",
      "Step:  199 Reward:  796.1518143238065\n",
      "Step:  200 Reward:  809.693650587032\n",
      "Step:  201 Reward:  792.4096673937032\n",
      "Step:  202 Reward:  780.1555888714989\n",
      "Step:  203 Reward:  775.7330176066355\n",
      "Step:  204 Reward:  795.509924880098\n",
      "Step:  205 Reward:  775.273025085527\n",
      "Step:  206 Reward:  805.1059685473048\n",
      "Step:  207 Reward:  776.0861673831087\n",
      "Step:  208 Reward:  790.7493029324162\n",
      "Step:  209 Reward:  788.5714411993484\n",
      "Step:  210 Reward:  821.4118132371025\n",
      "Step:  211 Reward:  780.9233608978934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  212 Reward:  787.9898567472259\n",
      "Step:  213 Reward:  798.245424417593\n",
      "Step:  214 Reward:  812.5406922540724\n",
      "Step:  215 Reward:  816.8370313005204\n",
      "Step:  216 Reward:  806.0943904107709\n",
      "Step:  217 Reward:  801.6658245913067\n",
      "Step:  218 Reward:  810.0815254150627\n",
      "Step:  219 Reward:  788.0677980137154\n",
      "Step:  220 Reward:  805.8545865670209\n",
      "Step:  221 Reward:  766.6891779902322\n",
      "Step:  222 Reward:  784.813321711613\n",
      "Step:  223 Reward:  779.7223742604356\n",
      "Step:  224 Reward:  786.5115053775412\n",
      "Step:  225 Reward:  806.6866515097743\n",
      "Step:  226 Reward:  796.5401889666128\n",
      "Step:  227 Reward:  769.4703062781543\n",
      "Step:  228 Reward:  797.5644370058382\n",
      "Step:  229 Reward:  806.4096261204887\n",
      "Step:  230 Reward:  802.3983622215785\n",
      "Step:  231 Reward:  807.27067766437\n",
      "Step:  232 Reward:  770.6829078800986\n",
      "Step:  233 Reward:  804.5397485365306\n",
      "Step:  234 Reward:  793.4934169361179\n",
      "Step:  235 Reward:  790.2583338915848\n",
      "Step:  236 Reward:  808.7887776667814\n",
      "Step:  237 Reward:  812.018443404976\n",
      "Step:  238 Reward:  779.8257196072896\n",
      "Step:  239 Reward:  819.3671456536418\n",
      "Step:  240 Reward:  804.413233493855\n",
      "Step:  241 Reward:  789.5078834516042\n",
      "Step:  242 Reward:  818.4984556265405\n",
      "Step:  243 Reward:  828.7141950272994\n",
      "Step:  244 Reward:  826.4700521256628\n",
      "Step:  245 Reward:  823.3931385922729\n",
      "Step:  246 Reward:  822.149528735736\n",
      "Step:  247 Reward:  812.9766893876284\n",
      "Step:  248 Reward:  848.0740436659939\n",
      "Step:  249 Reward:  832.4747467477126\n",
      "Step:  250 Reward:  819.2646113341141\n",
      "Step:  251 Reward:  799.6127366165338\n",
      "Step:  252 Reward:  822.6643530719605\n",
      "Step:  253 Reward:  823.1715915745917\n",
      "Step:  254 Reward:  832.331674555656\n",
      "Step:  255 Reward:  843.1218400198231\n",
      "Step:  256 Reward:  824.5661745013512\n",
      "Step:  257 Reward:  828.1287255166678\n",
      "Step:  258 Reward:  832.9773514560761\n",
      "Step:  259 Reward:  799.7249958538677\n",
      "Step:  260 Reward:  808.8616070435727\n",
      "Step:  261 Reward:  825.7908237910551\n",
      "Step:  262 Reward:  823.6819994733494\n",
      "Step:  263 Reward:  827.6118296661597\n",
      "Step:  264 Reward:  839.9741468092745\n",
      "Step:  265 Reward:  838.585309857252\n",
      "Step:  266 Reward:  837.8665357399151\n",
      "Step:  267 Reward:  841.1689918490308\n",
      "Step:  268 Reward:  855.4707812361302\n",
      "Step:  269 Reward:  836.0217319558236\n",
      "Step:  270 Reward:  825.6521247598916\n",
      "Step:  271 Reward:  846.4897585930534\n",
      "Step:  272 Reward:  847.037831406886\n",
      "Step:  273 Reward:  833.8373005266313\n",
      "Step:  274 Reward:  851.0149137199631\n",
      "Step:  275 Reward:  848.5232192457381\n",
      "Step:  276 Reward:  838.452659405899\n",
      "Step:  277 Reward:  869.1648637231729\n",
      "Step:  278 Reward:  855.4616597737953\n",
      "Step:  279 Reward:  843.7031451330562\n",
      "Step:  280 Reward:  860.4358154394183\n",
      "Step:  281 Reward:  843.6564290471496\n",
      "Step:  282 Reward:  857.8265345711828\n",
      "Step:  283 Reward:  863.3813065998479\n",
      "Step:  284 Reward:  859.9010694468395\n",
      "Step:  285 Reward:  855.8618086020766\n",
      "Step:  286 Reward:  847.9322370170014\n",
      "Step:  287 Reward:  854.8334704254804\n",
      "Step:  288 Reward:  862.7431339736095\n",
      "Step:  289 Reward:  859.9270762916052\n",
      "Step:  290 Reward:  833.8918676575062\n",
      "Step:  291 Reward:  862.1495819116767\n",
      "Step:  292 Reward:  848.0259048033424\n"
     ]
    }
   ],
   "source": [
    "def mkdir(base, name):\n",
    "    path = os.path.join(base, name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "monitor_dir = mkdir('exp4_(no_normalizer)','monitor')\n",
    "# monitor_dir = mkdir(work_dir, 'monitor')\n",
    "\n",
    "env_name = 'HalfCheetahBulletEnv-v0'\n",
    "np.random.seed(1)\n",
    "env = gym.make(env_name)\n",
    "env = wrappers.Monitor(env, monitor_dir, force=True)\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.shape[0]\n",
    "\n",
    "model = Model(num_steps,num_direction, num_top_direction, noise,1000)\n",
    "model.train(env, input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
